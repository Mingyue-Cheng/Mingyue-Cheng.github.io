<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mingyue Cheng's HomePage</title>
  <meta name="google-site-verification" content="kyHylTDUEgzODHrPnUw-S_22ahgQoswvjR1ui-JvdNk" />
  <link rel="stylesheet" href="./HomePage_files/bootstrap.min.css">
  <link rel="stylesheet" href="./HomePage_files/bootstrap.css">
  <style>
  </style>
</head>
<body data-gr-c-s-loaded="true">
<nav class="navbar navbar-inverse" role="navigation">

  <div class="container">
    <div class="row"></div>
    <div class="col-md-8">
      <div class="navbar-collapse collapse ">
        <ul class="nav navbar-nav" style="clear: both">
          <li class="active"><a class="navitme" href="https://mingyue-cheng.github.io/#home">Home</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#biography">Biography</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#education">Education</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#experience">Experience</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#publications">Pubications</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#honors">System</a> </li>
          <li><a class="navitme" href="https://mingyue-cheng.github.io/#honors">Honors</a> </li>
        </ul>
      </div>
    </div>
    </div>
    
</nav>

<div id="home" class="container">
  <div class="row">
    
    <div class="col-md-1 col-md-1">
      <!-- <div class="col-md-1 col-md-offset-1"> -->
      <img id="photo" class="img-rounded" style="margin-top:25px;margin-right:20px;" src="./HomePage_files/Mycheng-6.png" width="190px">
    </div>

    <div class="col-md-8 col-md-offset-1">
    <h2>Mingyue Cheng&nbsp;(ç¨‹æ˜æœˆ) &nbsp;
    <br>
    <br>

    <p style="font-size: 15.0pt">Ph.D, Associate Researcher</p>
    <p style="font-size: 12.0pt"> 
    <a href="https://dm.ustc.edu.cn/" target="_blank" rel="noopener">State Key Laboratory of Cognitive Intelligence</a>
    <br>
    <a href="http://cs.ustc.edu.cn/" target="_blank" rel="noopener">School of Computer Science and Technology, </a><a href="http://www.ustc.edu.cn/" target="_blank" rel="noopener">University of Science and Technology of China</a>
    <!-- <br>    -->
    <br>

    <br>

  <strong>Paper Profiles:</strong> 
  View on <a href="https://scholar.google.com/citations?user=74IhSx8AAAAJ&hl" target="_blank" rel="noopener">Google Scholar</a> and 
  <a href="https://dblp.org/pid/240/6202.html" target="_blank" rel="noopener">DBLP</a>.
    <br>


    <br>
    <strong>Research Group: </strong><a href="https://ustcagi.github.io/" target="_blank" rel="noopener">USTC-AGI Research Group</a>

    <br>
      </p>
      <p style="font-size: 10.5pt">
        <strong>Email:</strong>
          <a href="mailto:mycheng@ustc.edu.cn">mycheng@ustc.edu.cn&nbsp;&nbsp;</a>
          <br><strong>Add:</strong> B709, Xinzhi Building, Gaoxin Campus of USTC, Hefei, Anhui, China, 230031
      </p>

    </div>
  </div>
  <hr>
</div>



<div class="container">
  <h3 id="biography">Biography</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <p style="font-size: 13.0pt">
    I am an Associate Reseacher at <a href="http://cs.ustc.edu.cn/" target="_blank" rel="noopener"><strong>the School of Computer Science and Technology</strong></a>, <a href="http://www.ustc.edu.cn/" target="_blank" rel="noopener"><strong>USTC</strong></a>. I am also affiliated with the <a href="http://cogskl.iflytek.com/" target="_blank" rel="noopener"><strong>State Key Laboratory of Cognitive Intelligence</strong></a> at the side of USTC, working under the leadership of <a href="http://staff.ustc.edu.cn/~cheneh/" target="_blank" rel="noopener"><strong>Prof. Enhong Chen</strong></a> and <a href="http://staff.ustc.edu.cn/~qiliuql/" target="_blank" rel="noopener"><strong>Prof. Qi Liu</strong></a>. Previously, I obtained my Ph.D. degree under the supervision of <a href="http://staff.ustc.edu.cn/~qiliuql/" target="_blank" rel="noopener"><strong>Prof. Qi Liu </strong></a>.
  </p>
</div>

<div class="container">
  <h3 id="Research">Research Interests</h3>
  <hr style="border:0; background-color:black; height:1px;" size=0>
  <p style="font-size: 13.0pt">



    My research focuses on <u>time series and tabular data mining</u> and <u>large language model (LLM) reasoning and agents</u>, with the main goal of building <u>context-aware intelligent decision-making systems</u> to support <u>AI for Science</u> and <u>Recommender Systems</u>.


    <br>
    <ul style="font-size: 13.0pt"> 
<!--     <li>
      <strong>Time Series Analysis and Applications of Biomedical Big Data Mining:</strong> Specializing in building time series and sequence modeling algorithms from <u>low-level preprocessing and data representation to foundational modeling and the development of trustworthy machine learning algorithms tailored for multivariate time series</u>. Particularly, I am interested in exploring leveraging time series anlaysis technique for Biomedical Big Data Mining.
    </li> 
    
    <li>
      <strong>Large Language Models (LLMs) and Applications of AI4Science:</u></strong> Deeply committed to advancing the field of LLMs, with a particular focus on <u>retrieval-augmented generation (RAG)</u>, LLM-driven agent techniques. Particularly, I am intersted in exploring llm-based scientific Literature mining and domain reasoning task.
    </li>  -->
<!--     <li> <strong>Time Series Analysis:</strong> Focus on developing time series and sequence modeling algorithms, covering <u>preprocessing, data representation, foundational modeling, and reliable methods for multivariate time series</u>. Interested in applying these techniques to biomedical big data mining. 
    </li> 

    <li> <strong>Large Language Models (LLMs):</strong> Focus on advancing LLM research, particularly in <u>retrieval-augmented generation (RAG)</u> and <u>LLM-based Agents</u>. Interested in leveraging LLMs for AI4Science, mainly including scientific literature mining and domain-specific reasoning (E.g., Medical QA). 
    </li>
    
    <li>
      <strong>Recommender Systems:</strong> Specializing in <u>user behavior modeling</u>, including sequential and session-based recommendation, one-class learning with implicit feedback, automated machine learning techniques (e.g., NAS) for RecSys, and transfer learning in recommendation. 
    </li>  -->


    <!-- <li><strong>Time Series Analysis:</strong> Focus on developing time series and sequence modeling algorithms, including <u>time series forecasting, classification, foundation models, and data-centric and trustworthy AI methods</u>. We are particularly interested in applying these techniques to biomedical big data.</li> -->

<!--     <li><strong>Time Series Analysis:</strong> Focus on developing fundamental modeling theories and methods for time series data, including <u>forecasting, classification, and multimodal time series reasoning</u>, as well as advancing <u>time series foundation models</u>. We are particularly interested in integrating these techniques into <u>decision-making processes</u> and exploring their potential for <u>collaborative, context-aware decision support</u> in biomedical and other real-world applications.</li> 

    <li><strong>Tabular Data Mining:</strong> Focus on developing methods for table recognition, semantic understanding, and reasoning, including <u>structure parsing, content interpretation, and multi-hop reasoning</u>. We are particularly interested in applying these techniques to scientific literature tables to facilitate knowledge discovery in chemistry and biomedical domains.</li> -->


    <!-- <li><strong>Recommender Systems:</strong> Focus on <u>user behavior modeling</u>, including <u>sequential recommendation</u>, <u>one-class learning with implicit feedback</u>, and <u>automated recommendation strategies</u>. In addition, we are increasingly interested in <u>retrieval-augmented generation</u> for personalized recommendation and content synthesis.</li> -->


    <li><strong>Time Series and Tabular Data Mining:</strong> We develop core methods for <u>time series</u> and <u>tabular data</u>, focusing on <u>forecasting</u>, <u>classification</u>, <u>representation learning</u>, and <u>multimodal reasoning</u>. Our interests include <u>context-aware representations</u>, <u>non-stationary modeling</u>, and the development of <u>foundation models</u> for universal structured data representation.</li>


    <li><strong>LLM Reasoning and Agent:</strong> We aim to enhance <u>large language models</u> via <u>training-free contextual learning</u> and <u>reinforcement learning</u>, focusing on <u>long CoT reasoning</u>, <u>planning</u>, <u>long-context memory</u>, <u>tool use</u>, <u>self-reflection</u>, and <u>multi-agent collaboration</u>. Our objective is to build agents that can perceive, reason, and act autonomously in complex environments.</li>


    <li><strong>Artificial Intelligence for Science:</strong> We focus on two directions: (1) understanding <u>structured scientific data</u>, such as time series and tabular data; and (2) building <u>intelligent agents for scientific reasoning</u>, with abilities in inference, planning, and tool use. Our goal is to accelerate discovery by combining <u>data mining</u> and <u>LLM-driven reasoning</u> within autonomous agent systems.</li>


    <li><strong>Recommender Systems:</strong> Advance personalized recommendation through <u>sequential and spatio-temporal modeling</u> and <u>one-class collaborative filtering</u>. We investigate <u>reinforcement learning-based methods</u> and leverage <u>large language models</u> to enable <u>context-aware recommendation agents</u>. Our goal is to build generalizable frameworks for dynamic, real-world environments.
    </li> 


    </ul>

    <br>
    <p style="font-size: 13.0pt">
    æ¬¢è¿è„šè¸å®åœ°è€Œåˆç§¯æä¸»åŠ¨çš„æœ¬ç§‘ç”Ÿã€ç ”ç©¶ç”ŸåŒå­¦åŠ å…¥å®éªŒå®¤<a href="https://ustcagi.github.io/"><strong>USTC-AGI</strong></a>ç ”ç©¶ç»„ã€‚æ¬¢è¿ä½“éªŒæˆ‘ä»¬ç²¾å¿ƒæ‰“é€ çš„<a href="https://writelearn.bdaa.pro"><strong>ç§‘è¨€æ™ºèƒ½åŠ©å†™å¹³å°</strong></a>æå‡å†™ä½œæ•ˆç‡ä¸æŠ€èƒ½ã€‚
   </p>
  </p>
</div>


<!-- <div class="container">
  <h3 id="news">Latest News</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">


  <li><strong>[May. 2025]</strong> ğŸ‰ Congratulations to <strong>Shuo Yu</strong> and <strong>Jiahao Wang</strong> on their paper being accepted to <strong>CIKM 2025</strong>!</li>
  
  <li><strong>[Jul. 2025]</strong> ğŸ‰ Congratulations to <strong>Mingfan Pan</strong> and <strong>Yue Chen</strong> for their paper acceptance at <strong>RecSys 2025</strong>! </li>

  <li>
  <strong>[Jun. 2025]</strong> ğŸ“Š We released <strong>ChemTable</strong>, a large-scale dataset and benchmark for evaluating MLLMs on real-world chemical tables â€” one of the most structured and information-dense formats in scientific literature. 
  <a href="https://github.com/lqzxt/ChemTable" target="_blank">[GitHub]</a>
  <a href="https://arxiv.org/abs/2506.11375" target="_blank">[arXiv]</a>
  </li>

  <li><strong>[Jun. 2025]</strong> ğŸš€ We released <strong>Time-R1</strong>, the first time series reasoning model with reinforcement fine-tuning, now available on <a href="https://huggingface.co/ustc-zyt/Time-R1" target="_blank">Hugging Face</a> and <a href="https://github.com/lqzxt/Time-R1" target="_blank">GitHub</a>.</li>
  
  <li><strong>[May. 2025]</strong> ğŸ‰ Congratulations to <strong>Jie Ouyang</strong> and <strong>Junhao Yu</strong> on their paper being accepted to <strong>ACL 2025</strong>!</li>

  <li><strong>[May. 2025]</strong> ğŸ‰ Congratulations to <strong>Daoyu Wang</strong> and <strong>Zirui Liu</strong> on their paper being accepted to <strong>ICML 2025</strong>!</li>  

  <li><strong>[Apr. 2025]</strong> ğŸ‰ Congratulations to <strong>Jintao Zhang</strong>, <strong>Yitong Zhou</strong>, and <strong>Hao Zhang</strong> for having their paper accepted by <strong>IJCAI 2025</strong>!</li>

  <li><strong>[Apr. 2025]</strong> ğŸ“„ We have recently preprinted a new survey: <strong>A Comprehensive Survey of Time Series Forecasting: Concepts, Challenges, and Future Directions</strong> on <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.174430535.53879341" target="_blank" rel="noopener">TechRxiv</a>.</li>

  <li><strong>[Apr. 2025]</strong> ğŸ“„ Our new survey <strong>A Survey on Table Mining with Large Language Models: Challenges, Advancements and Prospects</strong> has just been released on <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.174352282.22844759" target="_blank" rel="noopener">TechRxiv</a>.</li>

  <li><strong>[Mar. 2025]</strong> ğŸš€ Our <strong>Agent R1</strong> project has been officially released on <a href="https://github.com/0russwest0/Agent-R1" target="_blank">GitHub</a>.</li>
  
  <li><strong>[Mar. 2025]</strong> ğŸ“„ Our survey <strong>A Survey on Knowledge-Oriented Retrieval-Augmented Generation</strong> has just been released on <a href="https://arxiv.org/pdf/2503.10677" target="_blank" rel="noopener">arXiv</a>.
  </li>
  
  <li><strong>[Dec. 2024]</strong> ğŸ† Congrats to our students on winning the <strong>Gold Award</strong> in the 2024 <strong>Ascend AI Innovation Competition</strong> finals!</li>


  </ul>
</div>
 -->


<style>
  .news-container {
    font-size: 13pt;
  }

  .toggle-button {
    background: none;
    border: none;
    color: #007bff;
    cursor: pointer;
    font-size: 12pt;
    margin-top: 8px;
    display: block;
    text-align: center;
    padding: 4px 0;
    transition: color 0.2s;
  }

  .toggle-button:hover {
    color: #0056b3;
    text-decoration: underline;
  }

  #moreNews li {
    margin-top: 6px;
  }
</style>

<div class="container">
  <h3 id="news">Latest News</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">

  <ul class="news-container" id="newsList">
    <!-- é»˜è®¤æ˜¾ç¤ºçš„æ–°é—» -->
  <li><strong>[Aug. 2025]</strong> ğŸš€ We released <strong>Science-Starï¼ˆç§‘æ˜Ÿï¼‰</strong>, an open-source framework for building, extending, and experimenting with scientific AI agents. <a href="https://github.com/Melmaphother/Science-Star" target="_blank">GitHub</a> 

  <li><strong>[Aug. 2025]</strong> ğŸ‰ Congratulations to <strong>Shuo Yu</strong> and <strong>Jiahao Wang</strong> on their paper being accepted to <strong>CIKM 2025</strong>!</li>
  
  <li><strong>[Jul. 2025]</strong> ğŸ‰ Congratulations to <strong>Mingfan Pan</strong> and <strong>Yue Chen</strong> for their paper acceptance at <strong>RecSys 2025</strong>! </li>

  <li>
  <strong>[Jun. 2025]</strong> ğŸ“Š We released <strong>ChemTable</strong>, a large-scale dataset and benchmark for evaluating MLLMs on real-world chemical tables â€” one of the most structured and information-dense formats in scientific literature. 
  <a href="https://github.com/lqzxt/ChemTable" target="_blank">[GitHub]</a>
  <a href="https://arxiv.org/abs/2506.11375" target="_blank">[arXiv]</a>
  </li>

    <!-- æŠ˜å å†…å®¹ -->
    <div id="moreNews" style="display: none;">
  
  <li><strong>[Jun. 2025]</strong> ğŸš€ We released <strong>Time-R1</strong>, the first time series reasoning model with reinforcement fine-tuning, now available on <a href="https://huggingface.co/ustc-zyt/Time-R1" target="_blank">Hugging Face</a> and <a href="https://github.com/lqzxt/Time-R1" target="_blank">GitHub</a>.</li>
  
  <li><strong>[May. 2025]</strong> ğŸ‰ Congratulations to <strong>Jie Ouyang</strong> and <strong>Junhao Yu</strong> on their paper being accepted to <strong>ACL 2025</strong>!</li>

  <li><strong>[May. 2025]</strong> ğŸ‰ Congratulations to <strong>Daoyu Wang</strong> and <strong>Zirui Liu</strong> on their paper being accepted to <strong>ICML 2025</strong>!</li>  

  <li><strong>[Apr. 2025]</strong> ğŸ‰ Congratulations to <strong>Jintao Zhang</strong>, <strong>Yitong Zhou</strong>, and <strong>Hao Zhang</strong> for having their paper accepted by <strong>IJCAI 2025</strong>!</li>

  <li><strong>[Apr. 2025]</strong> ğŸ“„ We have recently preprinted a new survey: <strong>A Comprehensive Survey of Time Series Forecasting: Concepts, Challenges, and Future Directions</strong> on <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.174430535.53879341" target="_blank" rel="noopener">TechRxiv</a>.</li>

  <li><strong>[Apr. 2025]</strong> ğŸ“„ Our new survey <strong>A Survey on Table Mining with Large Language Models: Challenges, Advancements and Prospects</strong> has just been released on <a href="https://www.techrxiv.org/doi/full/10.36227/techrxiv.174352282.22844759" target="_blank" rel="noopener">TechRxiv</a>.</li>

  <li><strong>[Mar. 2025]</strong> ğŸš€ Our <strong>Agent R1</strong> project has been officially released on <a href="https://github.com/0russwest0/Agent-R1" target="_blank">GitHub</a>.</li>
  
  <li><strong>[Mar. 2025]</strong> ğŸ“„ Our survey <strong>A Survey on Knowledge-Oriented Retrieval-Augmented Generation</strong> has just been released on <a href="https://arxiv.org/pdf/2503.10677" target="_blank" rel="noopener">arXiv</a>.
  </li>
  
  <li><strong>[Dec. 2024]</strong> ğŸ† Congrats to our students on winning the <strong>Gold Award</strong> in the 2024 <strong>Ascend AI Innovation Competition</strong> finals!</li>

    </div>
  </ul>

  <!-- ä¼˜é›…æŒ‰é’® -->
  <button class="toggle-button" onclick="toggleMoreNews()" id="toggleBtn">Show More â–¼</button>
</div>

<script>
  function toggleMoreNews() {
    const moreNews = document.getElementById("moreNews");
    const btn = document.getElementById("toggleBtn");
    if (moreNews.style.display === "none") {
      moreNews.style.display = "block";
      btn.textContent = "Show Less â–²";
    } else {
      moreNews.style.display = "none";
      btn.textContent = "Show More â–¼";
    }
  }
</script>




<div class="container">
  <h3 id="experience">Working Experiences</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">
  <li>Jun. 2023 ~ Present, Associate Researcher, School of Computer Science and Technology, USTC, 
      Hefei, China</li> 
  <li>Jan. 2021 ~ Jun. 2023, Research Assistant, Research Center for Big Data in Intelligent Healthcare, USTC, 
  Hefei, China</li> 
  <li>Jun. 2019 ~ Oct. 2019, Research Intern, Data Service Center (DSC), Platform and Conetnt Group (PCG), Tencent, Shenzhen, China</li> 
  <li>Jul.&nbsp; 2018 ~ Sep. 2018, Engineer Intern, Lab of Big Data, Core Technology R&amp;D Platform, iFLYTEK, Hefei, China</li>
  </ul>
</div>

<div class="container">
  <h3 id="education">Education</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">
    <li>Sep. 2017 ~ Jun. 2023, Major: Data Science (Computer Science and Technology), Ph.D Degree, <a href="http://www.ustc.edu.cn/" target="_blank" rel="noopener"><strong>University of Science and Technology of China (USTC)</strong></a>, China</li>
    <li>Sep. 2013 ~ Jul. 2017, Major: Marketing Management, Bachelor of Management, <a href="http://www.hfut.edu.cn/" target="_blank" rel="noopener"><strong>Hefei University of Technology (HFUT)</strong></a>, China</li>
  </ul>
</div>


<div class="container">
  <h3 id="selected publications">Selected Publications <a href="https://scholar.google.com/citations?user=74IhSx8AAAAJ&hl=zh-CN" target="_blank" rel="noopener"><small>(Google Scholar)</small></a>  <a href="https://github.com/Mingyue-Cheng" target="_blank" rel="noopener"> <small>(Github)</small></a></h3>
  <p>(* Corresponding Author, <sup>+</sup> Equal Contribution)</p>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <!-- <ol style="font-size: 12.0pt">   -->
    


  <!-- 2025 Publications -->
  <h4>ğŸ“˜ Preprint</h4>

  <ol style="font-size: 12pt">

    <!--     <li>
          Shuo Yu, <strong>Mingyue Cheng*</strong>, Jiqian Yang, Jie Ouyang, Yucong Luo, Chenyi Lei, Qi Liu, Enhong Chen, <strong>Multi-Source Knowledge Pruning for Retrieval-Augmented Generation: A Benchmark and Empirical Study</strong>. (Preprint)[<a href="https://ustc-rag-x.github.io/" target="_blank" rel="noopener">PDF</a>] [<a href="https://ustc-rag-x.github.io/" target="_blank" rel="noopener">Code</a>] 
        </li> -->

    <!--     <li>
          Yucong Luo, Qitao Qin, Hao Zhang, <strong>Mingyue Cheng</strong>, Ruiran Yan, Kefan Wang, Jie Ouyang , <strong>Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation</strong>. (Preprint)[<a href="https://arxiv.org/abs/2412.18176" target="_blank" rel="noopener">PDF</a>] 
        </li> -->



    <li>
      <strong>Mingyue Cheng</strong>, Jiahao Wang, Daoyu Wang, Xiaoyu Tao, Qi Liu*, Enhong Chen, <strong>Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting</strong>. (Preprint) [<a href="https://arxiv.org/pdf/2505.24511" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/realwangjiahao/TimeReasoner" target="_blank" rel="noopener">Code</a>] æ­ç¤ºäº†å…·å¤‡æ…¢æ€è€ƒèƒ½åŠ›çš„å¤§æ¨¡å‹åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æ¨ç†èƒ½åŠ›ä¸åº”ç”¨æ½œåŠ›ã€‚
    </li>

    <li>
      Xiaoyu Tao, Shilong Zhang,<strong>Mingyue Cheng*</strong>, Daoyu Wang, Tingyue Pan, Bokai Pan, Changqing Zhang, Shijin Wang, <strong>From Values to Tokens: An LLM-Driven Framework for Context-aware Time Series Forecasting via Symbolic Discretization</strong>. (Preprint) [<a href="https://www.arxiv.org/pdf/2508.09191" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Xiaoyu-Tao/TokenCast" target="_blank" rel="noopener">Code</a>] æ¢ç©¶äº†åŸºäºç¦»æ•£ç¼–ç çš„æ—¶åºæœªæ¥è¶‹åŠ¿æ¼”åŒ–é¢„æµ‹
    </li>

    <li>
      <strong>Mingyue Cheng</strong>, Qi Liu*, Zhiding Liu, Hao Zhang, Rujiao Zhang, Enhong Chen, <strong>TimeMAE: Self-supervised Representation of Time Series with Decoupled Masked Autoencoders</strong>. (Preprint) [<a href="https://arxiv.org/pdf/2303.00320" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/TimeMAE" target="_blank" rel="noopener">Code</a>] 
    </li>


    <li>
      <strong>Mingyue Cheng</strong>, Zhiding Liu, Xiaoyu Tao, Qi Liu*, Jintao Zhang, Tingyue Pan, Shilong Zhang, Panjing He, Xiaohan Zhang, Daoyu Wang, Jiahao Wang, Enhong Chen, <strong>A Comprehensive Survey of Time Series Forecasting: Concepts, Challenges, and Future Directions</strong>. (Preprint) [<a href="https://d197for5662m48.cloudfront.net/documents/publicationstatus/253323/preprint_pdf/0d1d8e876fb85a212190bc9200dcc3f3.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/USTCAGI/Awesome-Papers-Time-Series-Forecasting" target="_blank" rel="noopener">Code</a>] 
    </li>

    <li>
      <strong>Mingyue Cheng</strong>, Qingyang Mao, Qi Liu*, Yitong Zhou, Yupeng Li, Jiahao Wang, Jiaying Lin, Jiawei Cao, Enhong Chen,, <strong> A Survey on Table Mining with Large Language Models: Challenges, Advancements and Prospects</strong>. (Preprint) [<a href="https://d197for5662m48.cloudfront.net/documents/publicationstatus/252177/preprint_pdf/3d9c9b7d57481675d0d6e486c8bb7985.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/USTCAGI/Awesome-LLM-Table-Mining" target="_blank" rel="noopener">Code</a>] 
    </li>

    <li>
      <strong>Mingyue Cheng</strong>, Yucong Luo, Jie Ouyang, Qi Liu*, Huijie Liu, Li Li, Shuo Yu, Bohou Zhang, Jiawei Cao, Jie Ma, Daoyu Wang, Enhong Chen, <strong>A Survey on Knowledge-Oriented Retrieval-Augmented Generation</strong>. (Preprint) [<a href="https://arxiv.org/pdf/2503.10677" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/USTCAGI/Awesome-Papers-Retrieval-Augmented-Generation" target="_blank" rel="noopener">Code</a>] 
    </li>

    </ol>

    <h4>ğŸ“˜ 2025</h4>

    <ol style="font-size: 12pt">

    <li>
      Jiahao Wang, <strong>Mingyue Cheng*</strong>, Qingyang Mao, Qi Liu, Feiyang Xu, Xin Li, Enhong Chen, <strong>TableTime: Reformulating Time Series Classification as Zero-Shot Table Understanding via Large Language Models</strong>. (ACM CIKM2025, Accepted) [<a href="https://arxiv.org/pdf/2411.15737" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/realwangjiahao/TableTime" target="_blank" rel="noopener">Code</a>]
    </li>

     <li>
     Shuo Yu, <strong>Mingyue Cheng*</strong>, Jiqian Yang, Jie Ouyang, Yucong Luo, Chenyi Lei, Qi Liu, Enhong Chen, <strong>Multi-Source Knowledge Pruning for Retrieval-Augmented Generation: A Benchmark and Empirical Study</strong>. (ACM CIKM2025, Accepted)[<a href="https://ustc-rag-x.github.io/" target="_blank" rel="noopener">PDF</a>] [<a href="https://ustc-rag-x.github.io/" target="_blank" rel="noopener">Code</a>] 
    </li>


    <li> Mingfan Pan, Qingyang Mao, Xu An, Jianhui Ma, Gang Zhou, <strong>Mingyue Cheng</strong>, Enhong Chen, <strong>Tag-augmented Dual-target Cross-domain Recommendation</strong>. (RecSys2025, Accepted) </li> 

    <li> Yue Chen, Susen Yang, Tong Zhang, Chao Wang, <strong>Mingyue Cheng</strong>, Chenyi Lei, Han Li, <strong>Lasso: Large Language Model-based User Simulator for Cross-Domain Recommendation</strong>. (RecSys2025, Accepted) </li>


    <li>
      Jie Ouyang, Tingyue Pan, <strong>Mingyue Cheng*</strong>, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu, <strong>HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation</strong>. (ACL2025, Accepted) [<a href="https://arxiv.org/pdf/2503.04800" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/0russwest0/HoH" target="_blank" rel="noopener">Code</a>]
    </li> 



    <li>
      Junhao Yu, Yan Zhuang, Yuxuan Sun, Weibo Gao, Qi Liu, <strong>Mingyue Cheng</strong>, Zhenya Huang, Enhong Chen, <strong>TestAgent: An Adaptive and Intelligent Expert for Human Assessment</strong>. (ACL2025, Accepted) [<a href="https://arxiv.org/pdf/2503.04800" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/tinyy115/HiTime" target="_blank" rel="noopener">Code</a>]
    </li> 

    <li>
      Zirui Liu, Jiatong Li, Yan Zhuang, Qi Liu, Shuanghong Shen, Jie Ouyang, <strong>Mingyue Cheng</strong>, Shijin Wang, <strong>am-ELO: A Stable Framework for Arena-based LLM Evaluation</strong>. (ICML2025, Accepted) [<a href="https://arxiv.org/pdf/2505.03475" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Melmaphother/TimeDART" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
     Daoyu Wang, <strong>Mingyue Cheng*</strong>, Zhiding Liu, Qi Liu, <strong>TimeDART: A Diffusion Autoregressive Transformer for Self-supervised Time Series Representation</strong>. (ICML2025) [<a href="https://arxiv.org/html/2410.05711v1" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Melmaphother/TimeDART" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Jintao Zhang, Zhiding Liu, Chunli Liu*, Yanhu Xie, <strong>HMF: A Hybrid Multi-Factor Framework for Dynamic Intraoperative Hypotension Prediction</strong>. (IJCAI2025, Accepted) [<a href="https://www.arxiv.org/pdf/2409.11064" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Jintao Zhang, <strong>Mingyue Cheng*</strong>, Xiaoyu Tao, Zhiding Liu, Daoyu Wang, <strong>FDF: Flexible Decoupled Framework for Time Series Forecasting with Conditional Denoising and Polynomial Modeling</strong>. (IJCAI2025, Accepted) [<a href="https://arxiv.org/pdf/2410.13253" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/zjt-gpu/FDF" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Yitong Zhou, <strong>Mingyue Cheng*</strong>, <strong>Enhancing Table Recognition with Vision LLMs: A Benchmark and Neighbor-Guided Toolchain Reasoner</strong>. (IJCAI2025, Accepted) [<a href="https://arxiv.org/abs/2412.20662" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/lqzxt/NGTR" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Hao Zhang, <strong>Mingyue Cheng*</strong>, Qi Liu, Zhiding Liu, Linbo Zhu, Yu Su, <strong>Towards Automatic Sampling of User Behaviors for Sequential Recommender Systems</strong>. (IJCAI2025, Accepted)[<a href="https://arxiv.org/abs/2311.00388" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/zh-ustc/AutoSAM" target="_blank" rel="noopener">Code</a>] 
    </li>


    <li>
    <strong>Mingyue Cheng</strong>, Jiqian Yang, Tingyue Pan, Qi Liu*, Zhi Li, <strong>ConvTimeNet: A Deep Hierarchical Fully Convolutional Model for Multivariate Time Series Analysis</strong>. (ACM WWW2025, Accepted) [<a href="https://arxiv.org/pdf/2403.01493" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/ConvTimeNet" target="_blank" rel="noopener">Code</a>]
    </li>
    
    <li>
    <strong>Mingyue Cheng</strong>, Yiheng Chen, Qi Liu*, Zhiding Liu, Yucong Luo, Enhong Chen, <strong>InstructTime: Advancing Time Series Classification with Multimodal Language Modeling</strong>, The 18th ACM International Conference on Web Search and Data Mining (Accepted, ACM WSDM2025) [<a href="https://arxiv.org/pdf/2403.12371.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/InstructTime" target="_blank" rel="noopener">Code</a>] [<a href="./files/posters/instructtime-poster.pdf" target="_blank" rel="noopener">Poster</a>]
    </li>
    
    <li>
      <strong>Mingyue Cheng</strong>, Xiaoyu Tao, Qi Liu*, Hao Zhang, Yiheng Chen, Defu Lian, <strong>CrossTimeNet: Cross-Domain Pre-training with Language Models for Transferable Time Series Representations</strong>, The 18th ACM International Conference on Web Search and Data Mining (Accepted, ACM WSDM2025) [<a href="https://arxiv.org/pdf/2403.12372.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/CrossTimeNet" target="_blank" rel="noopener">Code</a>][<a href="./files/posters/crosstimenet-poster.pdf" target="_blank" rel="noopener">Poster</a>]
    </li>

      </ol>


  
    <h4>ğŸ“˜ 2024</h4>


    <ol style="font-size: 12pt">



    <li>
      Jie Ouyang, Yucong Luo, <strong>Mingyue Cheng*</strong>, Shuo Yu, Daoyu Wang, Qi Liu, Enhong Chen, <strong>Revisiting the Solution of Meta KDD Cup 2024: CRAG</strong>. (Accepted, 2024 KDD Cup Workshop for Retrieval Augmented Generation, <font color="red"><b>(Second Place in Task 2 & Task 3 of KDD Cup 2024)</b></font>)
      [<a href="https://ustc-rag-x.github.io/" target="_blank" rel="noopener">Code</a>][<a href="./files/posters/KDD-slide-v4.pdf" target="_blank" rel="noopener">Slides</a>][<a href="./files/posters/crag_kddcup.pdf" target="_blank" rel="noopener">Poster</a>].
    </li>

    <li>
      Rujiao Zhang, Hao Zhang, Yucong Luo, Zhiding Liu, <strong>Mingyue Cheng</strong>, Qi Liu, Enhong Chen*, <strong>Learning the Dynamics in Sequential Recommendation by Exploiting Real-time Information</strong>, <em>The 33rd ACM International Conference on Information and Knowledge Management</em> (ACM CIKM2024):4288 - 4292, October 21â€“25, 2024, Boise, ID, USA.  [<a href="https://dl.acm.org/doi/pdf/10.1145/3627673.3679955" target="_blank" rel="noopener">Code</a>][<a href="https://github.com/imsery/Dynamics/" target="_blank" rel="noopener">Slides</a>]
    </li>

    <li>
      Jie Wang, Fajie Yuan, <strong>Mingyue Cheng</strong>, Joemon M. Jose, Chenyun Yu, Beibei Kong, Zhijin Wang, Bo Hu, Zang Li, <strong>TransRec: Learning Transferable Recommendation from Mixture-of-Modality Feedback</strong>, <em>The 8th APWeb-WAIM Joint International Conference on Web and Big Data</em>ï¼ˆ<strong>APWeb-WAIM2024</strong>): 193-208, August 30 - September 1, Jinhua, China. [<a href="https://arxiv.org/pdf/2206.06190.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/icantnamemyself/GPHT" target="_blank" rel="noopener">Poster</a>]
    </li>

    <li>
      Zhiding Liu, Jiqian Yang, <strong>Mingyue Cheng*</strong>, Yucong Luo, Zhi Li, <strong>Generative Pretrained Hierarchical Transformer for Time Series Forecasting</strong>(<strong>ACM SIGKDD2024</strong>):2003-2013, August 25-29, 2024, Barcelona Spain, 2024. [<a href="https://arxiv.org/pdf/2402.16516.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="./files/posters/gpht_poster.pdf" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
      Yucong Luo, <strong>Mingyue Cheng</strong>, Hao Zhang, Junyu Lu, Enhong Chen*, <strong>Unlocking the Potential of Large Language Models for Explainable Recommendations</strong>. (DASFAA2024)[<a href="https://arxiv.org/pdf/2312.15661" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/GodFire66666/LLM_rec_explanation" target="_blank" rel="noopener">Code</a>]
    </li>
    
    <li>
    Junzhe Jiang, Shang Qu, <strong>Mingyue Cheng*</strong>, Qi Liu, Zhiding Liu, Hao Zhang, Rujiao Zhang, Kai Zhang, Rui Li, Jiatong Li, Min Gao, <strong>Reformulating Sequential Recommendation: Learning Dynamic User Interest with Content-enriched Language Modeling</strong>. (Accepted, DASFAA2024)[<a href="https://arxiv.org/pdf/2309.10435" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/Gnimixy/lancer" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Hao Zhang, Qi Liu*, Fajie Yuan, Zhi Li, Zhenya Huang, Enhong Chen, Longfei Li, Jun Zhou, <strong>Empowering Sequential Recommender Systems from Mixture of Collaborative Signals and Semantic Relatedness</strong>. (Accepted, DASFAA2024)[<a href="https://arxiv.org/pdf/2403.07623" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/Mingyue-Cheng/TSSR" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Hao Zhang, <strong>Mingyue Cheng*</strong>, Qi Liu, Yucong Luo, Rui Li, Enhong Chen, <strong>Learning Recommender Systems with Soft Target: A Decoupled Perspective</strong> (Accepted, DASFAA2024). [<a href="https://arxiv.org/pdf/2410.06536" target="_blank" rel="noopener">PDF</a>][<a href="https://github.com/zh-ustc/desorec/" target="_blank" rel="noopener">Code</a>][<a href="./files/posters/gpht_poster.pdf" target="_blank" rel="noopener">Poster</a>] 
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Hao Zhang, Jiqian Yang, Qi Liu*, Li Li, Xin Huang, Liwei Song, Zhi Li, Zhenya Huang, Enhong Chen, <strong>Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform</strong>. (WWW2024, Accepted)
    </li>

    <li>
    Junchen Fu, Fajie Yuan, Yu Song, Zheng Yuan, <strong>Mingyue Cheng</strong>, Shenghui Cheng, Jiaqi Zhang, Jie Wang, Yunzhu Pan, <strong>Exploring Adapter-based Transfer Learning for Recommender Systems: Empirical Studies and Practical Insights</strong>, The 17th ACM International Conference on Web Search and Data Mining (<strong>WSDM'2024</strong>): 208-217, Mar 4-8, 2024, MÃ©rida, MÃ©xico. [<a href="https://arxiv.org/pdf/2305.15036" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/westlake-repl/Adapter4Rec/" target="_blank" rel="noopener">Code</a>]
    </li>

      </ol>


  
    <h4>ğŸ“˜ 2023 and Before</h4>


    <ol style="font-size: 12pt">


    <li>
    Zhiding Liu, <strong>Mingyue Cheng</strong>, Zhi Li, Zhenya Huang, Qi Liu, Enhong Chen, <strong>Adaptive Normalization for Non-stationary Time Series Forecasting: A Temporal Slice Perspective</strong>, The 37th Advances in Neural Information Processing Systems (<strong>NeurIPS'2023</strong>):36, Dec 9-15, 2023, New Orleans, Louisiana, USA. [<a href="./files/papers/san-neurips2024.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/icantnamemyself/SAN" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
     è€¿æ°, åˆ˜æ˜¥ä¸½*, é­é›ªæ¢…, <strong>ç¨‹æ˜æœˆ</strong>, è¢æ˜†, ææ´‹, åˆ˜ä¸šæ”¿, <strong>åŸºäºç”¨æˆ·é‡è´­è¡Œä¸ºçš„äº§å“æ¨èæ–¹æ³•</strong>,  <em> è®¡ç®—æœºç ”ç©¶ä¸å‘å±• </em> 2023, 60(8): 1795-1807
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Qi Liu*, Wenyu Zhang, Zhiding Liu, Hongke Zhao, Enhong Chen, <strong>A General Tail Item Representation Enhancement Framework for Sequential Recommender Systems</strong>,  <em> Frontier of Comupter Science </em> (<strong>FCS</strong>), 2024, 18(6): 1-12. [<a href="./files/papers/tailrec-fcs2024.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/TailRec" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Qi Liu*, Zhiding Liu, Zhi Li, Yucong Luo, Enhong Chen, <strong>FormerTime: Hierarchical Multi-scale Representation for Multivariate Time Series Classification</strong>, <em> The 32nd International World Wide Web Conference</em> (<strong>ACM WWW'2023</strong>): 1437â€“1445, Austin, TX, USA. [<a href="./files/papers/formertime-www2023.pdf" target="_blank" rel="noopener">PDF</a>] [<a href="https://github.com/Mingyue-Cheng/FormerTime" target="_blank" rel="noopener">Code</a>]
    </li>
    
    <li>
    Wenqiang He, <strong>Mingyue Cheng</strong>, Qi Liu*, Zhi Li, <strong>ShapeWordNet: An Interpretable Shapelet Neural Network for Physiological Signal Classification</strong>, <em>  The 28th International Conference on Database Systems for Advanced Applications</em> (<strong>DASFAA'2023</strong>): 353â€“369, Tianjin, China.
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Zhiding Liu<sup>+</sup>, Qi Liu*, Shenyang Ge, Enhong Chen, <strong>Towards Automatic Designing of Deep Hybrid Network Architecture for Sequential Recommendation</strong>, <em> The 31st International World Wide Web Conference</em> (<strong>ACM WWW'2022</strong>):1923-1932, Virtual Conference. [<a href="https://github.com/Mingyue-Cheng/NASR" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Zhiding Liu, <strong>Mingyue Cheng</strong>, Zhi Li, Qi Liu, Enhong Chen*, <strong>One Person, One Modelâ€”Learning Compound Router for Sequential Recommendation</strong>, <em>The 22nd IEEE International Conference on Data Mining</em> (<strong>IEEE ICDM'2022</strong>).[<a href="https://github.com/Mingyue-Cheng/CANet" target="_blank" rel="noopener">Code</a>]
    </li>

    <li>
    Junzhe Jiang, <strong>Mingyue Cheng</strong>, Qi Liu*, Zhi Li, Enhong Chen, <strong>Nested Named Entity Recognition from Medical Texts: A Multi-task Learning Approach</strong>, <em>The Second CAAI International Conference on Artificial Intelligence </em> (<strong>CAAI CICAI'2022</strong>):248-259, Bejing, China.
    </li>

    <li>
      Runlong Yu, Qi Liu*, Yuyang Ye, <strong>Mingyue Cheng</strong>, Enhong Chen, Jianhui Ma, <strong>Collaborative List-and-Pairwise Filtering from Implicit Feedback</strong>, <em> IEEE Transactions on Knowledge and Data Engineering</em> (<strong>IEEE TKDE'2022</strong>): 34(6): 2667-2680, June 2022.
    </li>

    <li>
    Kai Zhang, Qi Liu*, Zhenya Huang, <strong>Mingyue Cheng</strong>, Kun Zhang, Mengdi Zhang, Wei Wu, Enhong Chen, <strong>Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification</strong>, <em> The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> (<strong>ACM SIGIR'2022</strong>): 1566-1576, Virtual Conference. 
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Fajie Yuan<sup>+</sup>, Qi Liu*, Xin Xin, Enhong Chen, <strong>Learning Transferrable User Representations with Sequential Behaviors via Contrastive Pre-training</strong>, <em> The 21st IEEE International Conference on Data Mining</em> (<strong>IEEE ICDM'2021</strong>):51-60, Auckland, New Zealand, December 7-10, 2021. 
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Fajie Yuan<sup>+</sup>, Qi Liu*, Shenyang Ge, Zhi Li, Runlong Yu, Defu Lian, Senchao Yuan, Enhong Chen, <strong>Learning Recommender Systems with Implicit Feedback via Soft Target Enhancement</strong>, <em> The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> ( <strong>ACM SIGIR'2021</strong>): 575-584, July 11â€“15, 2021, Virtual Event, Canada. 
    </li>

    <li>
    Linan Yue, Qi Liu*, Han Wu, Kai Zhang, Yanqing An, <strong>Mingyue Cheng</strong>, Biao Yin, Dayong Wu, <strong>NeurJudge: A Circumstance-aware Neural Framework for Legal Judgment Prediction</strong>, <em> The 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</em> ( <strong>ACM SIGIR'2021</strong>):973â€“982, July 11â€“15, 2021, Virtual Event, Canada. 
    </li>

    <li>
    Yanqing An, Qi Liu*, Han Wu, Kai Zhang, Linan Yue, <strong>Mingyue Cheng</strong>, Hongke Zhao, Senchao Yuan, Enhong Chen, <strong>LawyerPAN: A Proficiency Assessment Network for Trial Lawyers</strong>, <em> The 27th International ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em> (<strong>ACM SIGKDD'2021</strong>):5-13, August 14â€“18, 2021, Virtual Event, Singapore.
    </li>

    <li>
    <strong>Mingyue Cheng</strong>, Runlong Yu, Qi Liu*, Hongke Zhao, Hefu Zhang, Enhong Chen, <strong>Alpha-Beta Sampling for Pairwise Ranking in One-Class Collaborative Filtering</strong>, <em> The 19th IEEE International Conference on Data Mining </em>(<strong>IEEE ICDM'2019</strong>): 1000-1005, Beijing, China. 
    </li>

    <li>
    <strong>ç¨‹æ˜æœˆ</strong>, åˆ˜æ·‡*, æå¾µ, äºæ¶¦é¾™, é«˜ç»´åš, é™ˆæ©çº¢, <strong>å¤šé‡å¯¹çº§è´å¶æ–¯ä¸ªæ€§åŒ–æ’åºç®—æ³•</strong>. (<em>å—äº¬ä¿¡æ¯å·¥ç¨‹å¤§å­¦å­¦æŠ¥è‡ªç„¶ç§‘å­¦ç‰ˆ</em>: 2019å¹´03æœŸ302-308)
    </li>

  </ol>
</div>


<div class="container">
  <h3 id="opensource">Open Source Projects</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">

    <li>
      <strong>Science-Star</strong> â€” An open-source framework for building, extending, and experimenting with 
      <strong>scientific AI agents</strong>.  
      It provides a ReAct-based engine, tool orchestration, memory & reflection, 
      HLE dataset integration, and powerful visualization, enabling rapid development of 
      scientific agents from concept to deployment.  
      [<a href="https://github.com/Melmaphother/Science-Star" target="_blank" rel="noopener"><strong>GitHub</strong></a>]
    </li>

    <li>
      <strong>Agent-R1</strong> â€” A <strong>large-model agent training framework</strong> designed to enable 
      efficient alignment and reasoning capabilities for LLM-based agents.  
      It supports reinforcement fine-tuning (e.g., GRPO), multi-tool orchestration, long-term memory, 
      and reflective reasoning, accelerating the development of autonomous and context-aware agents.  
      [<a href="https://github.com/OpenBMB/Agent-R1" target="_blank" rel="noopener"><strong>GitHub</strong></a>]
    </li>


  </ul>
</div>



<div class="container">
  <h3 id="system">AI System Development</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <p style="font-size: 13.0pt">
    æˆ‘ä»¬å›¢é˜Ÿè‡´åŠ›äºç ”å‘é«˜æ•ˆä¸”å®ç”¨çš„AIç³»ç»Ÿï¼Œä»¥ä¸‹ä¸ºä¸€äº›æˆ‘ä»¬å›¢é˜Ÿç ”å‘çš„éƒ¨åˆ†ç³»ç»Ÿæˆæœï¼š
    <br>
    <ul style="font-size: 13.0pt">
      
      <li>
        <strong>å†°é‰´å¤§æ¨¡å‹è¯„æµ‹å¹³å°ï¼š</strong>
        <a href="https://bjllm.com/home" target="_blank" rel="noopener">å†°é‰´å¤§æ¨¡å‹è¯„æµ‹å¹³å°</a>ï¼Œå¤§æ¨¡å‹è®¤çŸ¥èƒ½åŠ›è¯„æµ‹å·¥å…·ã€‚
      </li>

      <li>
        <strong>ç§‘è¨€æ™ºèƒ½åŠ©å†™å¹³å°ï¼š</strong>
        <a href="https://writelearn.bdaa.pro" target="_blank" rel="noopener">ç§‘è¨€æ™ºèƒ½åŠ©å†™å¹³å°</a>ï¼Œæå‡å†™ä½œæ•ˆç‡ä¸æŠ€èƒ½ã€‚
      </li>

      <li>
        <strong>æ–‡é˜…å­¦ä½è®ºæ–‡è¾…åŠ©å®¡æŸ¥ï¼š</strong>
        <a href="https://tas.zhongkediman.com/" target="_blank" rel="noopener">æ–‡é˜…å­¦ä½è®ºæ–‡è¾…åŠ©å®¡æŸ¥</a>ï¼Œç ”ç©¶ç”Ÿå­¦ä½è®ºæ–‡è¾…åŠ©å®¡é˜…ã€‚
      </li>

      <li>
        <strong>ä¼ é“è‹±æ–‡ä½œä¸šæ™ºèƒ½æ‰¹é˜…ï¼š</strong>
        <a href="http://transdle.bdaa.pro/" target="_blank" rel="noopener">ä¼ é“å­¦ä½è®ºæ–‡è¾…åŠ©å®¡æŸ¥</a>ï¼Œå¤§å­¦è‹±è¯­å­¦ç”Ÿä½œä¸šè¾…åŠ©æ‰¹æ”¹ã€‚
      </li>

    </ul>
  </p>
</div>

<div class="container">
  <h3 id="honors">Honors and Awards</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">
  <li>Aug. 2025, ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦HWé’å¹´åŸºé‡‘äººæ‰</li>
  <li>Dec. 2024, æ˜‡è…¾äººå·¥æ™ºèƒ½åˆ›æ–°å¤§èµ›å…¨å›½æ€»å†³èµ›é‡‘å¥– (æŒ‡å¯¼æ•™å¸ˆ)</li>
  <li>Aug. 2024, Second Place of Task2&Task3 in Meta KDD Cup'2024</li>
  <li>Jan. 2024, ä¸­å›½ç§‘å¤§å­¦ç”Ÿé›„é¹°åˆ›æ–°åˆ›ä¸šåŸºé‡‘ (æŒ‡å¯¼æ•™å¸ˆ)</li>
  <li>Dec. 2023, 2023å¹´ä¸­å›½å›½é™…å¤§å­¦ç”Ÿåˆ›æ–°å¤§èµ›å›½å®¶çº§é“¶å¥–ï¼ˆæ•™è‚²éƒ¨ï¼‰</li>
  <li>Jul. 2023, å…¨å›½â€œäº’è”ç½‘+â€å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šå¤§èµ›å®‰å¾½çœé‡‘å¥–ï¼ˆå®‰å¾½çœæ•™è‚²å…ï¼‰</li>
  <li>Mar. 2023, ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</li>
  <li>May. 2022, 2022å¹´ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦â€œåˆ›æ–°åˆ›ä¸šâ€åŸºé‡‘ (ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦)</li>
  <li>Jan. 2022, ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦2022å¹´â€œä¼˜ç§€åšå£«ç”Ÿå‡ºå›½ç•™å­¦æ”¯æŒè®¡åˆ’â€ï¼ˆä¸­å›½ç§‘å¤§ç ”ç©¶ç”Ÿé™¢ï¼‰</li>
  <li>Dec. 2021, â€œåˆ›é’æ˜¥â€ä¸­å›½é’å¹´åˆ›æ–°åˆ›ä¸šé¡¹ç›®æ”¯æŒâ€”å¤§å­¦ç”Ÿåˆ›ä¸šâ€œé‡‘ç§å­â€è®¡åˆ’ï¼ˆå›¢ä¸­å¤®ï¼‰</li>
  <li>Sep. 2021, åšå£«ç ”ç©¶ç”Ÿå›½å®¶å¥–å­¦é‡‘ (æ•™è‚²éƒ¨)</li>
  <li>Sep. 2021, å…¨å›½â€œäº’è”ç½‘+â€å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šå¤§èµ›å®‰å¾½çœé‡‘å¥–ï¼ˆå®‰å¾½çœæ•™è‚²å…ï¼‰</li>
  <li>Jul. 2021, ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦â€œåº†å³°æ¯â€åˆ›æ–°åˆ›ä¸šå¤§èµ›äºŒç­‰å¥–(ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦)</li>
  <li>Jun. 2021, 2021å¹´ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦â€œåˆ›æ–°åˆ›ä¸šâ€åŸºé‡‘ (ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦)</li>
  <li>Sep. 2019, è…¾è®¯ç§‘æŠ€å¹³å°ä¸äº‹ä¸šç¾¤å®ä¹ ç”ŸMinié¡¹ç›®å“è¶Šå¥–</li>
  <li>Jul. 2018, å…¨å›½å¤§å­¦ç”Ÿâ€œåˆ›é’æ˜¥â€åˆ›æ–°åˆ›ä¸šå¤§èµ›å®‰å¾½çœé‡‘å¥–ï¼ˆå®‰å¾½çœæ•™è‚²å…ï¼‰</li>
  </ul>
</div>


<div class="container">
  <h3 id="honors">Teaching</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">
  <li>Introduction to Data Scienceï¼ˆæ•°æ®åˆ†æåŠå®è·µï¼‰, Undergraduate Course, Spring Semester, 2025.</li>
  </ul>
</div>




<div class="container">
  <h3 id="services">Professional Activities</h3>
  <hr style="border:0; background-color:black; height:1px;" size="0">
  <ul style="font-size: 13.0pt">
  <li><strong>Program Committee Member:</strong></li>
  
  <ul style="font-size: 12.0pt">
    <li>ACM International World Wide Web Conference (TheWebConf): 2024, 2025</li>
    <li>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD): 2023, 2024, 2025</li>
    <li>International Conference on Learning Representations (ICLR): 2025</li>
     <li>International Conference on Machine Learning (ICML): 2025</li>
    <li>Conference on Neural Information Processing Systems (NeurIPS): 2024, 2025</li>
    <li>Annual Meeting of the Association for Computational Linguistics (ACL): 2025</li>
    <li>International Joint Conference on Artificial Intelligence (IJCAI): 2024, 2025</li>
     <li>International Conference on Learning Representations (ICLR): 2025</li>
    <li>International Conference on Web Search and Data Mining: 2025</li>
    <li>SIAM International Conference on Data Mining (SDM): 2024</li>
    <li>ACM International Conference on Information and Knowledge Management: 2024, 2025</li>
    <li>Database Systems for Advanced Applications (DASFAA): 2024, 2025</li>
    <li><a href="https://cis.taskforce.ieee.org/ai4tst/" target="_blank">Task Force on AI for Time Series and Spatio-Temporal Data</a></li>

  </ul>

  <li><strong>Journal Reviewer:</strong></li>
  <ul style="font-size: 12.0pt">
    <li>IEEE Transactions on Knowledge and Data Engineering (IEEE TKDE)</li>
    <li>IEEE Transactions on Neural Network and Learning Systems (IEEE TNNLS)  </li>
    <li>IEEE Transactions on Audio, Speech and Language Processing (IEEE T-ASL)</li>
    <li>Neurocomputing</li>
    <li>Frontiers of Computer Science (FCS)</li>
    <li>è½¯ä»¶å­¦æŠ¥</li>
    <li>è®¡ç®—æœºå­¦æŠ¥</li>
  </ul>
  </ul>
</div>


<div class="container">
  <h3>Related Links</h3>
  <hr style="border:0; background-color:black; height:1px;" size=0>
  <ul style="font-size: 13.0pt">
    <li>Prof. <a href="http://staff.ustc.edu.cn/~qiliuql/" target="_blank" rel="noopener">Qi Liu</a> (USTC)</li>
    <li>Prof. <a href="http://staff.ustc.edu.cn/~cheneh/" target="_blank" rel="noopener">Enhong Chen</a> (USTC)</li>
    <li>Prof. <a href="https://fajieyuan.github.io/" target="_blank" rel="noopener">Fajie Yuan</a> (WU)</li>
    <li>Prof. <a href="http://come.tju.edu.cn/info/1526/5697.htm" target="_blank" rel="noopener">Hongke Zhao</a> (TJU)</li>

  <!--
    <li>USTC <a href="http://base.ustc.edu.cn" target="_blank" rel="noopener">BASE Group</a>, <a href="http://bigdata.ustc.edu.cn" target="_blank" rel="noopener">BDAA Lab.</a></li>
  -->
  </ul>
</div>

</body>
  
<!-- <footer>
    <div class="container" style="height: 12rem; width: 21rem;">
        <div style=""><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=yzpRvK6tscYP95eJAtp2KO6oJy1DQIIoLhPD5S-3EG8&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'></script></div>
    </div>
</footer>   -->

<!-- é¡µè„šåœ°å›¾ -->
<footer style="margin-top: 3rem; padding-bottom: 3rem;">
    <div class="container" style="height: 12rem; width: 21rem;">
        <div>
            <script type='text/javascript' id='clustrmaps'
                src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=yzpRvK6tscYP95eJAtp2KO6oJy1DQIIoLhPD5S-3EG8&co=2d78ad&ct=ffffff&cmo=3acc3a&cmn=ff5353'>
            </script>
        </div>
    </div>
</footer>

</html>
